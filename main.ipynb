{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "95a54fbe-2689-4a11-80f7-e99760fd9746",
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext jupyter_ai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "100a055c-c3e4-40af-8730-40abe6fe7e2c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "### Plotting with Matplotlib\n",
       "#### Import necessary libraries\n",
       "```python\n",
       "import matplotlib.pyplot as plt\n",
       "import numpy as np\n",
       "```\n",
       "#### Generate data for plotting\n",
       "```python\n",
       "# Create an array of x values\n",
       "x = np.linspace(0, 10, 100)\n",
       "\n",
       "# Define two different functions to plot\n",
       "def f(x):\n",
       "    return np.sin(x)\n",
       "def g(x):\n",
       "    return np.cos(x)\n",
       "\n",
       "# Evaluate the functions at x points and create arrays of y values\n",
       "y1 = f(x)\n",
       "y2 = g(x)\n",
       "\n",
       "# Create a plot with two lines\n",
       "plt.plot(x, y1, label='sin(x)')\n",
       "plt.plot(x, y2, label='cos(x)')\n",
       "```\n",
       "\n",
       "#### Customize the plot appearance\n",
       "```python\n",
       "# Set the title and labels\n",
       "plt.title('Plot of sin(x) and cos(x)')\n",
       "plt.xlabel('x')\n",
       "plt.ylabel('f(x)')\n",
       "\n",
       "# Add a legend\n",
       "plt.legend()\n",
       "\n",
       "# Show gridlines\n",
       "plt.grid(True)\n",
       "\n",
       "# Change the marker style\n",
       "plt.plot(x, y1, marker='o', linestyle='-')\n",
       "plt.plot(x, y2, marker='^', linestyle='--')\n",
       "\n",
       "# Set the x-axis limits and tick marks\n",
       "plt.xlim(0, 10)\n",
       "plt.xticks(np.linspace(0, 10, 5))\n",
       "\n",
       "# Show the plot\n",
       "plt.show()\n",
       "```\n",
       "This will generate a simple plot with two lines representing the sine and cosine functions.\n",
       "\n",
       "#### Additional Plot Features\n",
       "\n",
       "You can also add additional features to your plot, such as:\n",
       "\n",
       "*   Multiple plots on the same axis: `plt.plot(x1, y1, label='Line 1'); plt.plot(x2, y2, label='Line 2')`\n",
       "*   Scatter plot: `plt.scatter(x, y, s=10)`\n",
       "*   Histogram: `plt.hist(x, bins=5)`\n",
       "*   Bar chart: `plt.bar(x, y)`"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 4,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "llama3.2",
        "provider_id": "ollama"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai ollama:llama3.2\n",
    "\n",
    "\"plot a plot using matplotlib\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "570bdb44-78ec-49ec-8151-0d82d9a4bdfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "**Bayesian Personalized Ranking (BPR)**\n",
       "=====================================\n",
       "\n",
       "### Introduction\n",
       "\n",
       "Bayesian Personalized Ranking (BPR) is a widely used algorithm for recommendation systems that leverages Bayesian inference to learn user preferences from implicit feedback data, such as ratings or clicks.\n",
       "\n",
       "### Problem Statement\n",
       "\n",
       "The goal of BPR is to predict the relevance of items to each user based on their past behavior. The problem can be formulated as follows:\n",
       "\n",
       "* Given a set of users and items\n",
       "* Each user has a latent factor vector representing their preferences for items\n",
       "* Each item has a latent factor vector representing its characteristics\n",
       "* We want to learn the relationship between user latent factors and item latent factors\n",
       "\n",
       "### Algorithm Overview\n",
       "\n",
       "BPR is based on the idea of maximizing the likelihood of observed ratings given a set of latent factor vectors. The algorithm involves the following steps:\n",
       "\n",
       "1. **Distributed representation**: Represent users and items as high-dimensional vectors.\n",
       "2. **Loss function**: Define a loss function that measures the difference between predicted and true ratings.\n",
       "3. **Optimization**: Use stochastic gradient descent (SGD) to optimize the loss function.\n",
       "\n",
       "### Loss Function\n",
       "\n",
       "The BPR loss function is defined as:\n",
       "\n",
       "`L = -∑(u_i ∗ v_i - y_ij)^2`\n",
       "\n",
       "where:\n",
       "\n",
       "* `u_i` is the user latent factor vector\n",
       "* `v_i` is the item latent factor vector\n",
       "* `y_ij` is the true rating for item `i` by user `j`\n",
       "* The `-` sign indicates that we want to maximize the likelihood of observed ratings\n",
       "\n",
       "### Optimization\n",
       "\n",
       "The BPR loss function is optimized using stochastic gradient descent (SGD). At each iteration, we sample a batch of user-item pairs and compute the gradients of the loss function with respect to the latent factor vectors. We then update the weights to minimize the loss.\n",
       "\n",
       "### Advantages\n",
       "\n",
       "* **Interpretability**: BPR allows for interpretability of individual item features by analyzing the coefficients in the learned model.\n",
       "* **Efficient computation**: BPR can be computationally efficient, especially when using distributed representations and optimization methods.\n",
       "\n",
       "### Disadvantages\n",
       "\n",
       "* **Requires large amounts of data**: BPR requires a sufficient amount of labeled data to learn the user-item relationships.\n",
       "* **Sensitive to hyperparameters**: The choice of hyperparameters, such as learning rate and regularization strength, can significantly impact the performance of the algorithm.\n",
       "\n",
       "### Code Example (Python)\n",
       "```python\n",
       "import numpy as np\n",
       "\n",
       "def bpr_loss(user_item_pairs):\n",
       "    # Define the loss function\n",
       "    def loss(u, v, y):\n",
       "        return -np.mean((u @ v - y)**2)\n",
       "\n",
       "    # Compute the loss for each batch of user-item pairs\n",
       "    total_loss = 0\n",
       "    for u, v, y in user_item_pairs:\n",
       "        total_loss += loss(u, v, y)\n",
       "\n",
       "    return total_loss\n",
       "\n",
       "# Define a function to optimize the BPR loss using SGD\n",
       "def bpr_sgd(user_item_pairs, learning_rate, epochs):\n",
       "    # Initialize the weights\n",
       "    u_weights = np.random.rand(len(user_item_pairs), latent_dim)\n",
       "    v_weights = np.random.rand(latent_dim)\n",
       "\n",
       "    # Optimize the loss for each epoch\n",
       "    for epoch in range(epochs):\n",
       "        # Sample a batch of user-item pairs\n",
       "        batch_size = int(len(user_item_pairs) * 0.1)\n",
       "        indices = np.random.choice(len(user_item_pairs), batch_size, replace=False)\n",
       "        batch_user_item_pairs = [(user_item_pairs[i][0], user_item_pairs[i][1], user_item_pairs[i][2]) for i in indices]\n",
       "\n",
       "        # Compute the gradients of the loss function\n",
       "        u_gradients = []\n",
       "        v_gradients = []\n",
       "        for u, v, y in batch_user_item_pairs:\n",
       "            gradient_u = 2 * (u @ v - y)\n",
       "            gradient_v = 2 * (v @ u - y)\n",
       "            u_gradients.append(gradient_u)\n",
       "            v_gradients.append(gradient_v)\n",
       "\n",
       "        # Update the weights using SGD\n",
       "        u_weights -= learning_rate * np.mean(u_gradients, axis=0)\n",
       "        v_weights -= learning_rate * np.mean(v_gradients, axis=0)\n",
       "\n",
       "    return u_weights, v_weights\n",
       "\n",
       "# Define a function to predict ratings for new user-item pairs\n",
       "def bpr_predict(user_item_pairs, u_weights, v_weights):\n",
       "    # Compute the predicted ratings\n",
       "    predictions = []\n",
       "    for u, v, _ in user_item_pairs:\n",
       "        prediction = np.dot(u_weights, u) + np.dot(v_weights, v)\n",
       "        predictions.append(prediction)\n",
       "\n",
       "    return predictions\n",
       "\n",
       "# Example usage\n",
       "user_item_pairs = [(1, 101, 5), (2, 102, 4), ...]  # Replace with your own data\n",
       "learning_rate = 0.01\n",
       "epochs = 100\n",
       "latent_dim = 10\n",
       "\n",
       "u_weights, v_weights = bpr_sgd(user_item_pairs, learning_rate, epochs)\n",
       "predictions = bpr_predict(user_item_pairs, u_weights, v_weights)\n",
       "\n",
       "print(predictions)  # Print the predicted ratings for new user-item pairs\n",
       "```"
      ],
      "text/plain": [
       "<IPython.core.display.Markdown object>"
      ]
     },
     "execution_count": 3,
     "metadata": {
      "text/markdown": {
       "jupyter_ai": {
        "model_id": "llama3.2",
        "provider_id": "ollama"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai ollama:llama3.2\n",
    "\n",
    "\"explain what bayesian personalized ranking do\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "e6e8f99c-dfd9-4029-8032-23dc59aae69d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "AI generated code inserted below &#11015;&#65039;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 6,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "llama3.2",
        "provider_id": "ollama"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai ollama:llama3.2 -f code\n",
    "\n",
    "formula for pearson correlation, with sample data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "9289b61e-8a9d-4f22-8b6d-321009e74b8f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Pearson Correlation Coefficient: 0.5435164728414401\n"
     ]
    }
   ],
   "source": [
    "import numpy as np\n",
    "\n",
    "# Sample data\n",
    "x = np.array([1, 2, 3, 4, 5])\n",
    "y = np.array([2, 3, 5, 7, 11])\n",
    "\n",
    "mean_x = np.mean(x)\n",
    "mean_y = np.mean(y)\n",
    "\n",
    "n = len(x)\n",
    "\n",
    "r = (\n",
    "    (sum((x - mean_x) * (y - mean_y)))\n",
    "    / np.sqrt(sum(((x - mean_x) ** 2)) * n * sum((y - mean_y) ** 2))\n",
    ") * (n / (n - 1))\n",
    "\n",
    "print(\"Pearson Correlation Coefficient:\", r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "23643114-d250-4c29-83ff-a2fae61965cd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "AI generated code inserted below &#11015;&#65039;"
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "execution_count": 8,
     "metadata": {
      "text/html": {
       "jupyter_ai": {
        "model_id": "llama3.2",
        "provider_id": "ollama"
       }
      }
     },
     "output_type": "execute_result"
    }
   ],
   "source": [
    "%%ai ollama:llama3.2 -f code\n",
    "\n",
    "formula for pearson correlation, with sample data, but in golang"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "78cf2e37-c37c-439a-9a74-25986d1aeaa5",
   "metadata": {},
   "outputs": [],
   "source": [
    "package main\n",
    "\n",
    "import \"fmt\"\n",
    "\n",
    "func calculatePearsonCorrelation(x, y []float64) float64 {\n",
    "\tmeanX := sum(x) / len(x)\n",
    "\tmeanY := sum(y) / len(y)\n",
    "\tn := float64(len(x))\n",
    "\n",
    "\tnumerator := 0.0\n",
    "\tdenominator1 := 0.0\n",
    "\tdenominator2 := 0.0\n",
    "\n",
    "\tfor i := range x {\n",
    "\t\tnumerator += (x[i] - meanX)*(y[i] - meanY)\n",
    "\t\tdenominator1 += (x[i] - meanX)*(x[i] - meanX)\n",
    "\t\tdenominator2 += (y[i] - meanY)*(y[i] - meanY)\n",
    "\t}\n",
    "\n",
    "\treturn numerator / (\n",
    "\t\tsqrt(denominator1) * sqrt(n*denominator2)\n",
    "\t) * n / (n-1)\n",
    "}\n",
    "\n",
    "func sum(arr []float64) float64 {\n",
    "\tvar s float64\n",
    "\tfor _, v := range arr {\n",
    "\t\ts += v\n",
    "\t}\n",
    "\treturn s\n",
    "}\n",
    "\n",
    "func main() {\n",
    "\tx := []float64{1, 2, 3, 4, 5}\n",
    "\ty := []float64{2, 3, 5, 7, 11}\n",
    "\n",
    "\tr := calculatePearsonCorrelation(x, y)\n",
    "\tfmt.Println(\"Pearson Correlation Coefficient:\", r)\n",
    "}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "147b55cc-c023-4b52-9720-289b737d79e8",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
